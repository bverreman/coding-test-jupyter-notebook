{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"text-align: center; font-family: Arial\"> Two exercices to test python skills  </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Learning outcomes:**\n",
    "- Download/Upload from Dropbox\n",
    "- Edit cvs file using pandas\n",
    "- Web scraping\n",
    "- Ants Registration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Display with Notebook's built-in graphics library\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AntsPy version = 0.3.8\n",
      "SimpleITK version = 2.1.1.1\n"
     ]
    }
   ],
   "source": [
    "import pathlib #offer classes representing filesystem paths with semantics appropriate for different operating systems\n",
    "import dropbox #API for downloading/uploading from/to a dropbox account or case\n",
    "from dropbox.exceptions import AuthError\n",
    "\n",
    "import pandas as pd #open source data analysis and manipulation tool\n",
    "import random #generate random numbers\n",
    "from datetime import date,timedelta #manipulate dates (year, month, day)\n",
    "\n",
    "import nibabel as nib #supports an ever growing collection of neuroimaging file formats\n",
    "import requests #standard for making HTTP requests \n",
    "from bs4 import BeautifulSoup #library for parsing structured data\n",
    "\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from ipywidgets import interact\n",
    "import numpy as np\n",
    "import SimpleITK as sitk\n",
    "import cv2\n",
    "\n",
    "\n",
    "#from helpers import * #.py file from a tutorial\n",
    "import ants #AntsPy only used to visualize mask contour. Use ants from channel pnlbwh on terminal to get output files.\n",
    "import SimpleITK as sitk #Visualize MRI images\n",
    "import subprocess #Execute bash commands to use ANTS from PNLBWH\n",
    "\n",
    "#import itk #to do the automatic itk-skullstripping\n",
    "\n",
    "print(f'AntsPy version = {ants.__version__}')\n",
    "print(f'SimpleITK version = {sitk.__version__}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "project folder = /home/bverreman/Downloads/coding-test-jupyter-notebook\n"
     ]
    }
   ],
   "source": [
    "#print working directory\n",
    "BASE_DIR = os.path.dirname(os.path.abspath(\"__file__\"))\n",
    "print(f'project folder = {BASE_DIR}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercice I: Anonymize a dataset on Dropbox"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.** Set up the Dropbox application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "DROPBOX_ACCESS_TOKEN = 'sl.BfXIXkcZOAVQeXYYNRTb5uar0dXJD4c0tk8_4QZITkJS7n7OAIw0Jt7GJ3OmHULLQXdyH57YJlx0ZajGm_8KJ92eiyOhrWlJ82RxyPd_5YrPaixni1Le0DkB5HMTuKjGS6YSZzPr'\n",
    "#Security danger : unlimited access to my whole Dropbox account using this access token (use OAuth 2 instead to give authorization each time)\n",
    "#Access token only valid for 24 hours"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.** Connect to the Dropbox API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dropbox_connect():\n",
    "    \"\"\"Create a connection to Dropbox.\"\"\"\n",
    "\n",
    "    try:\n",
    "        dbx = dropbox.Dropbox(DROPBOX_ACCESS_TOKEN)\n",
    "    except AuthError as e:\n",
    "        print('Error connecting to Dropbox with access token: ' + str(e))\n",
    "    return dbx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.** Download the csv file from Dropbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dropbox_download_file(dropbox_file_path, local_file_path):\n",
    "    \"\"\"Download a file from Dropbox to the local machine.\"\"\"\n",
    "\n",
    "    try:\n",
    "        dbx = dropbox_connect()\n",
    "\n",
    "        with open(local_file_path, 'wb') as f:\n",
    "            metadata, result = dbx.files_download(path=dropbox_file_path)\n",
    "            f.write(result.content)\n",
    "    except Exception as e:\n",
    "        print('Error downloading file from Dropbox: ' + str(e))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Download the four files from Dropbox repository\n",
    "local_file_path=\"enroll_data.csv\"\n",
    "dropbox_file_path=\"/recruitment_project/\"+local_file_path\n",
    "dropbox_download_file(dropbox_file_path, local_file_path)\n",
    "\n",
    "local_file_path=\"atlas-T1w.nii.gz\"\n",
    "dropbox_file_path=\"/recruitment_project/\"+local_file_path\n",
    "dropbox_download_file(dropbox_file_path, local_file_path)\n",
    "\n",
    "local_file_path=\"atlas-integer-labels.nii.gz\"\n",
    "dropbox_file_path=\"/recruitment_project/\"+local_file_path\n",
    "dropbox_download_file(dropbox_file_path, local_file_path)\n",
    "\n",
    "local_file_path=\"given-T1w.nii.gz\"\n",
    "dropbox_file_path=\"/recruitment_project/\"+local_file_path\n",
    "dropbox_download_file(dropbox_file_path, local_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.** Read csv file and anonymize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def anonymization(f,f_anon,f_offset):\n",
    "    \"\"\"Create two csv files in working directory : \n",
    "    f_anon: anonymized data from the source file f (disguised date of consent and birth date replaced by age at date of consent)\n",
    "    f_offset: offset data used to deanonymize\n",
    "        \n",
    "    Args:\n",
    "        f (str): The name to the local source file.\n",
    "        f_anon (str): The name of the anonimized file.\n",
    "        f_offset (str): The name of the offset file.\n",
    "\n",
    "    Example:\n",
    "        dropbox_upload_file('enroll_data.csv', 'enroll_data_anon_BV.csv', 'enroll_data_offset_BV.csv')\n",
    "    \"\"\"\n",
    "    #Seed used for the reproductibility of the results and debugging. Should be removed to garantee anonymization.\n",
    "    random.seed(1) \n",
    "    \n",
    "    #Read enroll_data.csv\n",
    "    with open(f, 'r', newline='') as originF: \n",
    "        lines=originF.readlines()\n",
    "    \n",
    "    #Get date of consent and birth date values\n",
    "    df_anon = pd.DataFrame([x.split(',') for x in lines])\n",
    "    df_anon = df_anon.drop([0])\n",
    "    df_anon.rename(columns = {0:'site ID',1:'date of consent',2:'cohort',3:'birth date'}, inplace = True)\n",
    "    \n",
    "    consent=list(df_anon['date of consent'])\n",
    "    consent_list=[x.split('/') for x in consent]\n",
    "    \n",
    "    birth=list(df_anon['birth date'])\n",
    "    birth_list=[x.split('-') for x in birth]\n",
    "    \n",
    "    #Compute the new date of consent (with random offset)\n",
    "    #Compute the age at the original date of consent\n",
    "    new_consent=[]\n",
    "    new_age=[]\n",
    "    new_offset=[]\n",
    "    for i in range(len(consent)):\n",
    "        consent_date = date(year=int(consent_list[i][2]),month=int(consent_list[i][0]),day=int(consent_list[i][1]))\n",
    "        \n",
    "        birth_date = date(year=int(birth_list[i][0]),month=int(birth_list[i][1]),day=int(birth_list[i][2]))\n",
    "        age=consent_date.year-birth_date.year\n",
    "        if consent_date.month<birth_date.month:\n",
    "            age+=1\n",
    "        elif consent_date.month==birth_date.month:\n",
    "            if consent_date.day<=birth_date.day:\n",
    "                age+=1\n",
    "        new_age.append(age)\n",
    "            \n",
    "        offset=random.randint(35065, 37065) #96years between 1924 and 2020: 25*366+71*365=35065 days exactly\n",
    "        new_consent_date=consent_date-timedelta(days=offset) #days substraction\n",
    "        \n",
    "        new_date=str(new_consent_date.month)+'/'+str(new_consent_date.day)+'/'+str(new_consent_date.year)\n",
    "        new_consent.append(new_date)\n",
    "        \n",
    "        new_offset.append(offset)\n",
    "        \n",
    "    #Update anonymization dataframe (df_anon) and create offset dataframe (df_offset)\n",
    "    df_anon.drop('date of consent', inplace=True, axis=1)\n",
    "    df_anon.insert (1, 'date of consent', new_consent)\n",
    "    \n",
    "    df_anon.drop('birth date', inplace=True, axis=1)\n",
    "    df_anon.insert (3, 'age', new_age)\n",
    "    print(df_anon)\n",
    "    \n",
    "    df_offset = pd.DataFrame(new_offset,columns=['offset'])\n",
    "    print(df_offset)\n",
    "        \n",
    "    #Write the two csv files\n",
    "    df_anon.to_csv(f_anon)\n",
    "    df_offset.to_csv(f_offset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     site ID date of consent cohort  age\n",
      "1        BWH       3/31/1923    CHR   31\n",
      "2        BWH      10/23/1920    CHR   32\n",
      "3        BWH        4/2/1919     HC   23\n",
      "4        BWH        7/3/1919     HC   34\n",
      "5        BWH       9/20/1919    CHR   35\n",
      "...      ...             ...    ...  ...\n",
      "7942     PNC       1/22/1920    CHR   21\n",
      "7943     PNC      11/30/1924     HC   32\n",
      "7944     PNC       1/18/1923    CHR   33\n",
      "7945     PNC      11/29/1920    CHR   24\n",
      "7946     PNC       9/26/1919    CHR   35\n",
      "\n",
      "[7946 rows x 4 columns]\n",
      "      offset\n",
      "0      35340\n",
      "1      36230\n",
      "2      36800\n",
      "3      36708\n",
      "4      36629\n",
      "...      ...\n",
      "7941   36869\n",
      "7942   35095\n",
      "7943   35777\n",
      "7944   36557\n",
      "7945   36987\n",
      "\n",
      "[7946 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "f = \"enroll_data.csv\"\n",
    "f_anon = \"enroll_data_anon_BV.csv\"\n",
    "f_offset = \"enroll_data_offset_BV.csv\"\n",
    "anonymization(f,f_anon,f_offset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5.** Upload the files to Dropbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dropbox_upload_file(local_path, local_file, dropbox_file_path):\n",
    "    \"\"\"Upload a file from the local machine to a path in the Dropbox app directory.\n",
    "\n",
    "    Args:\n",
    "        local_path (str): The path to the local file.\n",
    "        local_file (str): The name of the local file.\n",
    "        dropbox_file_path (str): The path to the file in the Dropbox app directory.\n",
    "\n",
    "    Example:\n",
    "        dropbox_upload_file('.', 'test.csv', '/stuff/test.csv')\n",
    "\n",
    "    Returns:\n",
    "        meta: The Dropbox file metadata.\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        dbx = dropbox_connect()\n",
    "\n",
    "        local_file_path = pathlib.Path(local_path) / local_file\n",
    "\n",
    "        with local_file_path.open(\"rb\") as f:\n",
    "            meta = dbx.files_upload(f.read(), dropbox_file_path, mode=dropbox.files.WriteMode(\"overwrite\"))\n",
    "\n",
    "            return meta\n",
    "    except Exception as e:\n",
    "        print('Error uploading file to Dropbox: ' + str(e))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_file=\"enroll_data_anon_BV.csv\"\n",
    "dropbox_file_path=\"/recruitment_project/\"+local_file\n",
    "dropbox_upload_file(\"\", local_file, dropbox_file_path)\n",
    "\n",
    "local_file=\"enroll_data_offset_BV.csv\"\n",
    "dropbox_file_path=\"/recruitment_project/\"+local_file\n",
    "dropbox_upload_file(\"\", local_file, dropbox_file_path);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercice II: Ants Registration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.** Web scrapping: FreeSurfer Look up table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      label                         name\n",
      "0         0                      Unknown\n",
      "1         1       Left-Cerebral-Exterior\n",
      "2         2   Left-Cerebral-White-Matter\n",
      "3         3         Left-Cerebral-Cortex\n",
      "4         4       Left-Lateral-Ventricle\n",
      "...     ...                          ...\n",
      "1287  14171           wm_rh_S_suborbital\n",
      "1288  14172          wm_rh_S_subparietal\n",
      "1289  14173         wm_rh_S_temporal_inf\n",
      "1290  14174         wm_rh_S_temporal_sup\n",
      "1291  14175  wm_rh_S_temporal_transverse\n",
      "\n",
      "[1292 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "url = \"https://surfer.nmr.mgh.harvard.edu/fswiki/FsTutorial/AnatomicalROI/FreeSurferColorLUT\"\n",
    "\n",
    "page = requests.get(url)\n",
    "\n",
    "soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "results = soup.find(id=\"content\") #Find the 'div' with id=content\n",
    "res=results.text #Remove html code to only keep text\n",
    "\n",
    "with open(\"LookUpTable.txt\", \"w+\") as f:\n",
    "    f.write(res)\n",
    "    f.seek(0) #put file pointer at the start\n",
    "    lines=f.readlines()\n",
    "with open(\"LookUpTable.txt\", \"w+\") as f:\n",
    "    for line in lines[:-1]:\n",
    "        if not line.startswith('#') and not line.startswith('\\n'):\n",
    "            f.write(line)\n",
    "    line=lines[-1]\n",
    "    f.write(line.split('*')[0]) #remove comment on last line \n",
    "    f.seek(0) \n",
    "    lines=f.readlines()\n",
    "\n",
    "#Create pandas dataframe\n",
    "df = pd.DataFrame([x.split() for x in lines])\n",
    "df.rename(columns = {0:'label',1:'name'}, inplace = True)\n",
    "table=df[['label','name']]\n",
    "table=table.astype({'label': 'int'})\n",
    "#print(type(table.at[0,\"label\"]))\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.** Visual aspect of raw image, atlas and atlas integer labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_info(img_sitk,img_name):\n",
    "    \"\"\"Show information of an MRI image\n",
    "\n",
    "    Args:\n",
    "        img_name: MRI image in working directory\n",
    "\n",
    "    Example:\n",
    "        show_info(img_sitk,\"given-T1w.nii.gz\")\n",
    "    \"\"\"\n",
    "    print(\"\\n\"+\"Image : \"+img_name)\n",
    "    \n",
    "    pixel_type = img_sitk.GetPixelIDTypeAsString()\n",
    "    origin = img_sitk.GetOrigin()\n",
    "    dimensions = img_sitk.GetSize()\n",
    "    spacing = img_sitk.GetSpacing()\n",
    "    direction = img_sitk.GetDirection()\n",
    "\n",
    "    info = {'Pixel Type' : pixel_type, 'Dimensions': dimensions, 'Spacing': spacing, 'Origin': origin,  'Direction' : direction}\n",
    "    for k,v in info.items():\n",
    "        print(f' {k} : {v}')\n",
    "\n",
    "    img_sitk_arr = sitk.GetArrayFromImage(img_sitk)\n",
    "    print(f'type = {type(img_sitk_arr)}')\n",
    "    print(f'shape = {img_sitk_arr.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image(img_sitk,orientation1='LAS',orientation2='AIR',cmap='gray') : #Orientation (X,Y,Z), into the direction: Right-Left/Inferior-Superior/Posterior-Anterior\n",
    "    \"\"\"Show an MRI image with slice bar using simpleITK and in two orientations\n",
    "\n",
    "    Args:\n",
    "        img_name: MRI image in working directory using simpleITK\n",
    "        orientation1: orientation of the first image showed\n",
    "        orientation2: orientation of the second image showed\n",
    "\n",
    "    Example:\n",
    "        show_image(\"given-T1w.nii.gz\",'LAS','AIR')\n",
    "    \"\"\"\n",
    "    def fn(SLICE):\n",
    "        plt.figure(figsize=(7,7))\n",
    "        plt.imshow(img_sitk_arr[SLICE, :, :], cmap=cmap)\n",
    "    \n",
    "    img_sitk_cp = sitk.DICOMOrient(img_sitk,orientation1)\n",
    "    img_sitk_arr=sitk.GetArrayFromImage(img_sitk_cp)\n",
    "    interact(fn, SLICE=(0, img_sitk_arr.shape[0]-1))\n",
    "\n",
    "    img_sitk_cp = sitk.DICOMOrient(img_sitk,orientation2)\n",
    "    img_sitk_arr=sitk.GetArrayFromImage(img_sitk_cp)\n",
    "    interact(fn, SLICE=(0, img_sitk_arr.shape[0]-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_compare(img1_sitk,img2_sitk,orientation1='LAS',orientation2='AIR',cmap='nipy_spectral') : #Orientation (Z,Y,X), from the direction: Right-Left/Inferior-Superior/Posterior-Anterior\n",
    "    \"\"\"Show two same sized MRI images from working directory with slice bar using simpleITK and in two orientations\n",
    "\n",
    "    Args:\n",
    "        img1_sitk: First MRI image with simpleITK\n",
    "        img2_sitk: Second MRI image with simpleITK (same size)\n",
    "        orientation1: orientation of the first couple of image showed\n",
    "        orientation2: orientation of the second couple of image showed\n",
    "        cmap: color of cmap\n",
    "\n",
    "    Example:\n",
    "        show_compare(cropped_img_sitk,\n",
    "        corrected_image_full_resolution, \n",
    "        orientation1='LAS',\n",
    "        orientation2='AIR',\n",
    "        cmap='gray')\n",
    "    \"\"\"    \n",
    "    def fn(SLICE):\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, sharex='col', sharey='row', figsize=(10,10))\n",
    "\n",
    "        ax1.set_title('Before', fontsize=15)\n",
    "        ax1.imshow(img1_sitk_arr[SLICE, :, :], cmap=cmap)\n",
    "\n",
    "        ax2.set_title('After', fontsize=15)\n",
    "        ax2.imshow(img2_sitk_arr[SLICE, :, :], cmap=cmap)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        \n",
    "    img1_sitk_cp = sitk.DICOMOrient(img1_sitk,orientation1)\n",
    "    img1_sitk_arr = sitk.GetArrayFromImage(img1_sitk_cp)\n",
    "    \n",
    "    img2_sitk_cp = sitk.DICOMOrient(img2_sitk,orientation1)\n",
    "    img2_sitk_arr = sitk.GetArrayFromImage(img2_sitk_cp)\n",
    "    \n",
    "    assert img1_sitk_arr.shape == img2_sitk_arr.shape\n",
    "    \n",
    "    interact(fn, SLICE=(0, img1_sitk_arr.shape[0]-1))\n",
    "    \n",
    "    img1_sitk_cp = sitk.DICOMOrient(img1_sitk,orientation2)\n",
    "    img1_sitk_arr = sitk.GetArrayFromImage(img1_sitk_cp)\n",
    "    img2_sitk_cp = sitk.DICOMOrient(img2_sitk,orientation2)\n",
    "    img2_sitk_arr = sitk.GetArrayFromImage(img2_sitk_cp)\n",
    "    \n",
    "    interact(fn, SLICE=(0, img1_sitk_arr.shape[0]-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rescale_linear(array: np.ndarray, new_min: int, new_max: int):\n",
    "    \"\"\"Rescale an array linearly.\n",
    "    \n",
    "    Args:\n",
    "        array: a array to rescale (type ndarray)\n",
    "        new_min: new minimum value\n",
    "        new_max: new maximum value\n",
    "    \n",
    "    Return:\n",
    "        an array rescaled\n",
    "\n",
    "    Example:\n",
    "        rescale_linear(img_ants_arr,0,1)\n",
    "    \"\"\"\n",
    "    minimum, maximum = np.min(array), np.max(array)\n",
    "    m = (new_max - new_min) / (maximum - minimum)\n",
    "    b = new_min - m * minimum\n",
    "    return m * array + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_superpose(img_name,mask_name,orientation1='SAL',orientation2='RIA',thickness: int = 1) : #Orientation (Z,Y,X) : Right-Left/Inferior-Superior/Posterior-Anterior\n",
    "    \"\"\"Superposes the outline of the mask on the corresponding MRI image \n",
    "    Apply a threshold on mask (integer labels) to make it binary\n",
    "    Both images are from working directory \n",
    "    Also shows a slice bar, uses AntsPy and shows two orientations\n",
    "\n",
    "    Args:\n",
    "        img_name: MRI image name\n",
    "        mask_name: MRI mask image name (same size)\n",
    "        orientation1: orientation of the first couple of image showed\n",
    "        orientation2: orientation of the second couple of image showed\n",
    "        thickness: thickness of the outline in pixel (int)\n",
    "\n",
    "    Example:\n",
    "        show_superpose(\"corrected-T1w.nii.gz\",\n",
    "        label_to_corrected.nii.gz,\n",
    "        orientation1='SAL',\n",
    "        orientation2='RIA')\n",
    "    \"\"\"\n",
    "    def fn(SLICE):\n",
    "        arr_rgb = cv2.cvtColor(_arr[SLICE, :, :], cv2.COLOR_GRAY2RGB)\n",
    "        contours, _ = cv2.findContours(_mask[SLICE, :, :], cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "        arr_with_contours = cv2.drawContours(arr_rgb, contours, -1, (0,1,0), thickness)\n",
    "\n",
    "        plt.figure(figsize=(7,7))\n",
    "        plt.imshow(arr_with_contours)\n",
    "    \n",
    "    img_ants = ants.image_read(BASE_DIR+\"/\"+img_name, reorient='IPL')\n",
    "    mask_ants = ants.image_read(BASE_DIR+\"/\"+mask_name, reorient='IPL')\n",
    "    mask_ants=ants.threshold_image(mask_ants, low_thresh=1,high_thresh=255)\n",
    "    \n",
    "    img_ants_arr=img_ants.numpy()\n",
    "    mask_ants_arr=mask_ants.numpy()\n",
    "    \n",
    "    assert img_ants_arr.shape == mask_ants_arr.shape\n",
    "    \n",
    "    _arr = rescale_linear(img_ants_arr,0,1)\n",
    "    _mask = rescale_linear(mask_ants_arr,0,1)\n",
    "    _mask = _mask.astype(np.uint8)\n",
    "    \n",
    "    interact(fn, SLICE=(0, img_ants_arr.shape[0]-1))\n",
    "    \n",
    "    img_ants = ants.image_read(BASE_DIR+\"/\"+img_name, reorient='RSP')\n",
    "    mask_ants = ants.image_read(BASE_DIR+\"/\"+mask_name, reorient='RSP')\n",
    "    mask_ants=ants.threshold_image(mask_ants, low_thresh=1,high_thresh=255)\n",
    "    \n",
    "    img_ants_arr=img_ants.numpy()\n",
    "    mask_ants_arr=mask_ants.numpy()\n",
    "    \n",
    "    _arr = rescale_linear(img_ants_arr,0,1)\n",
    "    _mask = rescale_linear(mask_ants_arr,0,1)\n",
    "    _mask = _mask.astype(np.uint8)\n",
    "    \n",
    "    interact(fn, SLICE=(0, img_ants_arr.shape[0]-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Image : given-T1w.nii.gz\n",
      " Pixel Type : 32-bit float\n",
      " Dimensions : (176, 256, 256)\n",
      " Spacing : (0.9999160170555115, 0.9999999403953552, 0.9999999403953552)\n",
      " Origin : (-87.66697692871094, 111.55906677246094, -157.77081298828125)\n",
      " Direction : (1.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, 0.0, 1.0)\n",
      "type = <class 'numpy.ndarray'>\n",
      "shape = (256, 256, 176)\n"
     ]
    }
   ],
   "source": [
    "img_name=\"given-T1w.nii.gz\"\n",
    "img_sitk = sitk.ReadImage(BASE_DIR+\"/\"+img_name, sitk.sitkFloat32)\n",
    "show_info(img_sitk,img_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Image : atlas-T1w.nii.gz\n",
      " Pixel Type : 32-bit float\n",
      " Dimensions : (182, 218, 182)\n",
      " Spacing : (1.0, 1.0, 1.0)\n",
      " Origin : (-90.0, 126.0, -72.0)\n",
      " Direction : (1.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, 0.0, 1.0)\n",
      "type = <class 'numpy.ndarray'>\n",
      "shape = (182, 218, 182)\n"
     ]
    }
   ],
   "source": [
    "img_name=\"atlas-T1w.nii.gz\"\n",
    "img_sitk = sitk.ReadImage(BASE_DIR+\"/\"+img_name, sitk.sitkFloat32)\n",
    "show_info(img_sitk,img_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fcc9145d0eb4f26816b3361a2c28681",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=127, description='SLICE', max=255), Output()), _dom_classes=('widget-int…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80023d20a52747cd96a26f1c99f456d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=87, description='SLICE', max=175), Output()), _dom_classes=('widget-inte…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img_sitk = sitk.ReadImage(BASE_DIR+\"/\"+\"given-T1w.nii.gz\", sitk.sitkFloat32)\n",
    "show_image(img_sitk,'LAS','AIR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b89e6b64ba3d42b3927f00c64a0620c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=90, description='SLICE', max=181), Output()), _dom_classes=('widget-inte…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d7377abeb0b439ba997af093bfb5929",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=90, description='SLICE', max=181), Output()), _dom_classes=('widget-inte…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img_path=BASE_DIR+\"/\"+\"atlas-T1w.nii.gz\"\n",
    "img_sitk = sitk.ReadImage(img_path, sitk.sitkFloat32)\n",
    "show_image(img_sitk,'LAS','AIR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3cb52354e004ff79226e2059c487d42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=90, description='SLICE', max=181), Output()), _dom_classes=('widget-inte…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53c063b6e29d4ab89fab9889c1297239",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=90, description='SLICE', max=181), Output()), _dom_classes=('widget-inte…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img_path=BASE_DIR+\"/\"+\"atlas-integer-labels.nii.gz\"\n",
    "img_sitk = sitk.ReadImage(img_path, sitk.sitkFloat32)\n",
    "show_image(img_sitk,'LAS','AIR')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Visual observations:**\n",
    "- The raw image has a lot of white noise inside the white and the gray matter respectively\n",
    "- The face on the raw image is masked to guarantee the anonymity\n",
    "- The brains on both the raw image and the atlas are centered and aligned, but they are not the same relative size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Recommendations for pre-processing**\n",
    "- Crop the raw image to get a relative brain size indentical to the atlas\n",
    "- Use Bias Field Correction on the raw image to reduce the noise both inside the white and the gray matter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.** Pre-processing before registration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.1** Cropping the raw image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cropping(img_name,set1=(0,0,0),set2=(0,0,0),orientation1='LAS',orientation2='AIR'):\n",
    "    \"\"\"Crop an MRI image from working directory using simpleITK.\n",
    "    Also show resulting image in two orientations.\n",
    "\n",
    "    Args:\n",
    "        img_name: MRI image name\n",
    "        set1: number of pixels cropped in direction (Right,Posterior,Superior)\n",
    "        set2: number of pixels cropped in direction (Left,Anterior,Inferior)\n",
    "        orientation1: orientation of the first image showed\n",
    "        orientation2: orientation of the second image showed\n",
    "\n",
    "    Example:\n",
    "        cropping(\"given-T1w.nii.gz\",(5,20,70),(5,40,10))\n",
    "    \"\"\"\n",
    "    img_sitk = sitk.ReadImage(BASE_DIR+\"/\"+img_name, sitk.sitkFloat32)\n",
    "    img_sitk = sitk.Crop(img_sitk,set1,set2)\n",
    "\n",
    "    img_sitk = sitk.DICOMOrient(img_sitk,orientation1)\n",
    "    show_image(img_sitk,orientation1='LAS',orientation2='AIR',cmap='gray')  \n",
    "    \n",
    "    img_sitk = sitk.DICOMOrient(img_sitk,orientation2)\n",
    "    show_image(img_sitk,orientation1='LAS',orientation2='AIR',cmap='gray') \n",
    "    \n",
    "    return img_sitk\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3f5baaf86934da1b2d427de6ba7cbd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=87, description='SLICE', max=175), Output()), _dom_classes=('widget-inte…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a9eee22a835497b9c4aa7f2697d54e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=82, description='SLICE', max=165), Output()), _dom_classes=('widget-inte…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "156ac4ef05ce49d3be05e969cebeccf2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=87, description='SLICE', max=175), Output()), _dom_classes=('widget-inte…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab9a9d92afca41c5adce3cd122a9b181",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=82, description='SLICE', max=165), Output()), _dom_classes=('widget-inte…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cropped_img_sitk=cropping(\"given-T1w.nii.gz\",(5,20,70),(5,40,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.2** Use Bias Field Correction\n",
    "- We will use N4 Bias Field Correction (SimpleITK) on the cropped image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create head mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "187402fea1624fd4b53c7f1bf17359d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=87, description='SLICE', max=175), Output()), _dom_classes=('widget-inte…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1bc7fc95fc94a2d9452a3f6cc9769a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=82, description='SLICE', max=165), Output()), _dom_classes=('widget-inte…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "inputImage = cropped_img_sitk\n",
    "\n",
    "head_mask = sitk.RescaleIntensity(inputImage , 0, 255)\n",
    "head_mask = sitk.LiThreshold(head_mask,0,1)\n",
    "\n",
    "show_compare(inputImage,\n",
    "            head_mask, \n",
    "            cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bias Correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "shrinkFactor = 4\n",
    "\n",
    "inputImage = sitk.Shrink(cropped_img_sitk, [ shrinkFactor ] * inputImage.GetDimension() )\n",
    "maskImage = sitk.Shrink( head_mask, [ shrinkFactor ] * inputImage.GetDimension() )\n",
    "\n",
    "bias_corrector = sitk.N4BiasFieldCorrectionImageFilter()\n",
    "\n",
    "corrected = bias_corrector.Execute(inputImage, maskImage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get image corrected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15b24d7f33664792b551470c282ec8cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=87, description='SLICE', max=175), Output()), _dom_classes=('widget-inte…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c7df83f4e164c81bd0535efb4bd3fdf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=82, description='SLICE', max=165), Output()), _dom_classes=('widget-inte…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "log_bias_field = bias_corrector.GetLogBiasFieldAsImage(cropped_img_sitk)\n",
    "corrected_image_full_resolution = cropped_img_sitk / sitk.Exp( log_bias_field )\n",
    "\n",
    "show_compare(cropped_img_sitk,\n",
    "            corrected_image_full_resolution, \n",
    "            cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "sitk.WriteImage(corrected_image_full_resolution, BASE_DIR+\"/corrected-T1w.nii.gz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.** Ants Registration of raw image (mobile) to atlas (fixed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Two command lines:**\n",
    "- Registration of the corrected image **'corrected-T1w.nii.gz'** to the atlas **'atlas-T1w.nii.gz'** to get the output of the affine transform **'corrected_to_atlas_0GenericAffine.mat'** and the inverse displacement field **'corrected_to_atlas_1InverseWarp.nii.gz'** \n",
    "- Apply the reverse transform on the label image **'atlas-integer-labels.nii.gz'** to get **'label_to_corrected.nii.gz'**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create bash script\n",
    "with open ('ants_registration.sh', 'w') as rsh:\n",
    "    rsh.write('''\\\n",
    "#! /bin/bash\n",
    "antsRegistrationSyNQuick.sh -d 3 -f atlas-T1w.nii.gz -m corrected-T1w.nii.gz -o corrected_to_atlas_ -n 4\n",
    "antsApplyTransforms -d 3 -i atlas-integer-labels.nii.gz -r corrected-T1w.nii.gz -o label_to_corrected.nii.gz -t [corrected_to_atlas_0GenericAffine.mat, 1] -t corrected_to_atlas_1InverseWarp.nii.gz -n NearestNeighbor\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed!\n"
     ]
    }
   ],
   "source": [
    "#Give access to bash script\n",
    "process = subprocess.Popen([\"chmod\", \"u+x\", \"ants_registration.sh\"])\n",
    "process.wait()\n",
    "\n",
    "print(\"Completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Execute bash script : \n",
    "#exit_code = subprocess.call('./ants_registration.sh')\n",
    "#print(exit_code)\n",
    "\n",
    "#Instead, use command line in terminal: ./ants_registration.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a000a97b5d0b4f19a7eff4d6c4691662",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=87, description='SLICE', max=175), Output()), _dom_classes=('widget-inte…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef8a8c4e5cb946bf9bda5d9bf319dcfa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=82, description='SLICE', max=165), Output()), _dom_classes=('widget-inte…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Compare labels in different colors with the image of interest\n",
    "img1_sitk = sitk.ReadImage(BASE_DIR+\"/\"+\"corrected-T1w.nii.gz\", sitk.sitkFloat32)\n",
    "img2_sitk = sitk.ReadImage(BASE_DIR+\"/\"+\"label_to_corrected.nii.gz\", sitk.sitkFloat32)\n",
    "show_compare(img1_sitk,img2_sitk,cmap='nipy_spectral')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "906d5443558747458fad9bf3ede164fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=87, description='SLICE', max=175), Output()), _dom_classes=('widget-inte…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "114879f3b4f545679f9d37f5d27ffe63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=82, description='SLICE', max=165), Output()), _dom_classes=('widget-inte…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Superpose the merged labels on the corrected image\n",
    "show_superpose(\"corrected-T1w.nii.gz\",\"label_to_corrected.nii.gz\",thickness=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5.** Thresholding on integer labels and volume extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_label_im(im):\n",
    "    \"\"\"Compute statistics on an image using sitk.LabelShapeStatisticsImageFilter class.\n",
    "    \n",
    "    Argument : sitk image in integer format (sitkInt32 for example)\n",
    "\n",
    "    Return the list of label indexes and their respective size.\n",
    "    \"\"\"\n",
    "\n",
    "    labstats = sitk.LabelShapeStatisticsImageFilter()\n",
    "    labstats.Execute(im)\n",
    "    labels = list(labstats.GetLabels())\n",
    "    sizes=[labstats.GetNumberOfPixels(i) for i in labels]\n",
    "\n",
    "    return labels,sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "im= sitk.ReadImage(BASE_DIR+\"/label_to_corrected.nii.gz\", sitk.sitkInt32)\n",
    "labels,sizes=process_label_im(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create pandas dataframe\n",
    "data = {'label': labels,\n",
    "        'volume': sizes}\n",
    "\n",
    "volume = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    label                           name  volume\n",
      "0       1         Left-Cerebral-Exterior   12740\n",
      "1       2     Left-Cerebral-White-Matter    1366\n",
      "2       3           Left-Cerebral-Cortex    6999\n",
      "3       4         Left-Lateral-Ventricle    9259\n",
      "4       5              Left-Inf-Lat-Vent    9264\n",
      "5       6       Left-Cerebellum-Exterior     373\n",
      "6       7   Left-Cerebellum-White-Matter    1132\n",
      "7       8         Left-Cerebellum-Cortex    1151\n",
      "8       9                  Left-Thalamus     495\n",
      "9      10          Left-Thalamus-Proper*     515\n",
      "10     11                   Left-Caudate     625\n",
      "11     12                   Left-Putamen     678\n",
      "12     13                  Left-Pallidum     704\n",
      "13     14                  3rd-Ventricle     658\n",
      "14     15                  4th-Ventricle    1552\n",
      "15     16                     Brain-Stem    1556\n",
      "16     17               Left-Hippocampus    1916\n",
      "17     18                  Left-Amygdala    1818\n",
      "18     19                    Left-Insula    2403\n",
      "19     20                 Left-Operculum    2422\n",
      "20     21                         Line-1    1536\n",
      "21     22                         Line-2    1602\n",
      "22     23                         Line-3    3917\n",
      "23     24                            CSF    3666\n",
      "24     25                    Left-Lesion    4233\n",
      "25     26            Left-Accumbens-area    4146\n",
      "26     27          Left-Substancia-Nigra    2258\n",
      "27     28                 Left-VentralDC    2375\n",
      "28     29              Left-undetermined    2363\n",
      "29     30                    Left-vessel    2361\n",
      "30     31            Left-choroid-plexus    1416\n",
      "31     32                     Left-F3orb    1469\n",
      "32     33                       Left-lOg    4243\n",
      "33     34                       Left-aOg    4235\n",
      "34     35                       Left-mOg    1686\n",
      "35     36                       Left-pOg    2049\n",
      "36     37                  Left-Stellate     815\n",
      "37     38                      Left-Porg     781\n",
      "38     39                      Left-Aorg     741\n",
      "39     40        Right-Cerebral-Exterior     752\n",
      "40     41    Right-Cerebral-White-Matter    3762\n",
      "41     42          Right-Cerebral-Cortex    3953\n",
      "42     43        Right-Lateral-Ventricle     275\n",
      "43     44             Right-Inf-Lat-Vent     286\n",
      "44     45      Right-Cerebellum-Exterior     259\n",
      "45     46  Right-Cerebellum-White-Matter     257\n",
      "46     47        Right-Cerebellum-Cortex     351\n",
      "47     48                 Right-Thalamus     308\n"
     ]
    }
   ],
   "source": [
    "#Merge the volume dataframe with the look up table from Freesurfer\n",
    "result = pd.merge(table,volume,on=\"label\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save into csv file\n",
    "local_file=\"result_of_registration_BV.csv\"\n",
    "result.to_csv(local_file)\n",
    "\n",
    "#Send it to Dropbox repository\n",
    "dropbox_file_path=\"/recruitment_project/\"+local_file\n",
    "dropbox_upload_file(\"\", local_file, dropbox_file_path);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Improvement ideas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Use automatic ITK-SkullStrip before Bias Field Correction to remove background noise and background artifacts (try to convert between itk and simpleITK)\n",
    "- Create a pipeline\n",
    "- Find a permanent method to access Dropbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
